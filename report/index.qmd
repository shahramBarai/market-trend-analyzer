---
format:
  acm-pdf:
    include-in-header: header.tex

# use keep-tex to cause quarto to generate a .tex file
# which you can eventually use with TAPS
# keep-tex: true

bibliography: bibliography.bib

title: Market Trend Analyzer

author:
  - name: Yerzhan Zhamashev
    note: Both authors contributed equally to this work.
    email: yerzhan.zhamashev@aalto.fi
    affiliation:
      name: Aalto University
      city: Espoo
      country: Finland
  - name: Shahram Barai*
    email: shahram.barai@aalto.fi
    affiliation:
      name: Aalto University
      city: Espoo
      country: Finland

# acm-specific metadata
acm-metadata:
  # comment this out to make submission anonymous
  # anonymous: true

  # comment this out to build a draft version
  final: true

  # comment this out to specify detailed document options
  acmart-options: sigconf

  # acm preamble information
  copyright-year: 2024
  acm-year: 2024
  copyright: rightsretained

  # The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
  # Please copy and paste the code instead of the example below.
  ccs: |
    \begin{CCSXML}
    <ccs2012>
      <concept>
        <concept_id>10002951.10002952</concept_id>
        <concept_desc>Information systems~Data management systems</concept_desc>
        <concept_significance>500</concept_significance>
        </concept>
      <concept>
        <concept_id>10011007.10011074</concept_id>
        <concept_desc>Software and its engineering~Software creation and management</concept_desc>
        <concept_significance>300</concept_significance>
        </concept>
      <concept>
        <concept_id>10010405.10010406</concept_id>
        <concept_desc>Applied computing~Enterprise computing</concept_desc>
        <concept_significance>300</concept_significance>
      </concept>
    </ccs2012>
    \end{CCSXML}

    \ccsdesc[500]{Information systems~Data management systems}
    \ccsdesc[300]{Software and its engineering~Software creation and management}
    \ccsdesc[300]{Applied computing~Enterprise computing}

  keywords:
    - data analysis
    - data visualization
    - real-time data
    - financial data
    - decision support
    - system performance

abstract: |
  This is a course project report for the course "CS-E4780 - Scalable Systems and Data Management D" at Aalto University. The project addresses the analysis of financial tick data to detect trading trends by implementing a system capable of identifying price movement patterns for individual symbols and generating actionable buy/sell advisories. Using a real-world dataset comprising one week of high-frequency market events across multiple European exchanges, two primary analyses were conducted: (1) calculating Exponential Moving Averages (EMAs) over fixed time windows to detect short-term price trends and (2) identifying bullish and bearish breakout patterns to generate buy and sell advisories, respectively. The developed system also includes a visualization component to highlight detected patterns, enhancing trader decision-making capabilities. Evaluation focuses on performance, scalability, and accuracy in processing high-volume event streams.
---

# Introduction

The detection of trading trends in financial markets is a critical task for analysts and traders. With the rapid growth of market data, the need for systems capable of processing and analyzing high-frequency data in real time has become more pressing. This project, performed as part of the “CS-E4780 - Scalable Systems and Data Management D” course at Aalto University, aims to address this challenge by developing a system that detects trading trends and provides actionable buy/sell advisories.

The system leverages a real-world dataset consisting of one week’s worth of financial tick data collected from multiple European exchanges. The project implements two primary analyses: calculating Exponential Moving Averages (EMAs) to detect price trends and identifying bullish and bearish breakout patterns to generate buy and sell advisories. The system also includes a visualization component to display the detected trends and advisories, although it is still under development.

The architecture of the system is built to handle real-time data streams. The first component is the real-time data producer, which emulates a real-time stream of financial data by preprocessing a large CSV file and splitting events by event ID (share symbol + region) using a Python script. This data is then passed to a series of worker processes written in Rust with the Tokio library, which synchronizes and sends the data to Kafka topics based on the event region. Kafka acts as the buffer for this event data, ensuring scalability and reliability.

For real-time analytics, the project uses Flink to process events in 5-minute windows, with each task manager subscribing to a specific Kafka topic (representing a region) to handle relevant data. The output of this analysis is sent back to the Kafka analytics topic, which the client can subscribe to to access the processed results. This data informs the detection of price trends and breakout patterns, leading to actionable buy and sell advisories.

Web dashboard for visializing the result....

Kubernetes for auto-scaling the system ....

## Data Set

The data used for this course project are based on a week’s worth of real tick data captured by Infront Financial Technology GmbH in 2021. The full data set Trading Data used for the project is publicly available from @frischbier_2022_6382482 licensed under an open license[^1].

[^1]: [http://creativecommons.org/licenses/by-nc-sa/4.0/](http://creativecommons.org/licenses/by-nc-sa/4.0/)

# System Architecture

The Market Trend Analyzer’s architecture is designed with a focus on scalability, real-time processing, and efficient handling of high-volume financial data streams. It consists of multiple components, each selected and implemented to meet specific requirements for efficient data ingestion, processing, analysis, and delivery of market insights. The following diagram illustrates the system architecture and the data flow between these components.

![Context view](images/context_view.jpg)

We use Docker and Docker Compose to containerize and orchestrate all system components. Containerization simplifies deployment, ensuring the system runs consistently across different environments—be it a local machine, cloud provider, or Kubernetes cluster. The decision to use Docker and Docker Compose was driven by the need for a straightforward deployment process and environment consistency.

The system is divided into several services, each representing a different component: the real-time data producer, Kafka, Flink, TimescaleDB, and the web application. Each service has its own Dockerfile defining base images, dependencies, and configurations. Docker Compose then orchestrates these services, specifying their relationships and dependencies, which simplifies the overall setup and management.

## Producer for Real-time Data Generation
The producer component is split into two parts: subscription to a data source and a producer module. The subscription part fetches real-time market data, while the producer module processes and routes this data to the appropriate Kafka topics. This design ensures that the system can handle high-frequency, real-world events rather than relying on pre-fetched or batch data. The goal is to simulate real-time data streams and validate the system’s ability to handle large volumes of events effectively.

Both parts of the producer are implemented in Rust, using the Tokio library for asynchronous processing. Rust was chosen for its high performance, memory safety, and concurrency support. Tokio’s asynchronous runtime allows the system to handle multiple concurrent connections and non-blocking I/O efficiently. Together, Rust and Tokio enable the system to process data streams in real time and manage high-frequency events without performance bottlenecks.

![Producer service](images/producer_service.jpg)

### Subscription to a data source
We first split a large CSV file into smaller files by share symbol and region using a Python script. Python was chosen for this initial data processing step due to its ease of use and flexibility. Because this step is only performed once before the system runs, Python’s performance overhead is not critical.

After splitting the data, we use Rust (with Tokio) to create a pool of worker tasks that read the CSV data and send it to the producer module according to the original trading times. This approach allows us to simulate real-time data ingestion by reproducing the original event order and timing, ensuring that the system genuinely processes events in a streaming manner.

### Producer features
The producer module subscribes to the data source and routes the incoming events to the correct Kafka topics. We chose to implement the producer in Rust as well, maintaining language consistency with the subscription workers and simplifying integration and code reuse.

An alternative considered was Elixir, known for its suitability in distributed, fault-tolerant, and highly concurrent systems. Elixir provides lightweight concurrency and built-in fault tolerance, making it an attractive option for real-time data processing. However, we opted for Rust to keep the system architecture simpler and reduce the number of technologies. By using Rust end-to-end in the producer subsystem, we ensure that high-frequency data streams are handled efficiently and reliably.

Another key design decision was to use Protobuf for data serialization before sending messages to Kafka. Protobuf’s binary serialization format is highly efficient in both size and speed, outperforming JSON or XML for high-throughput data systems. This choice reduces network overhead and improves overall performance.

In addition to Protobuf, we apply Snappy compression to the serialized data before sending it to Kafka. Snappy offers excellent compression and decompression speeds, making it a great fit for a high-throughput, low-latency system. Compared to other algorithms like Gzip, Zstd, or LZ4, Snappy strikes a good balance between compression ratio and speed, further optimizing performance and reducing network bandwidth usage.

## Kafka for Data Buffer
Apache Kafka is used as the data buffer to store and manage the high-volume event data generated by the real-time data producer. Kafka provides a scalable, fault-tolerant, and distributed messaging system that can handle large amounts of data efficiently. By using Kafka, the system can ensure that data is reliably stored and processed, even in the event of failures or network issues. The decision to partition the data by region in Kafka aligns with the need to process events based on their geographical origin, enabling efficient data processing and analysis. Kafka's ability to handle high-throughput data streams and provide real-time data processing capabilities makes it an ideal choice for the system's architecture. 

The decision to devide the data by region is based on the limited resources. In real world, the data should be divided by the symbol of the share. This way, consumers can subscribe to the data (i.e. Kafka topics) based on the share symbol they are interested in. This allows for more efficient data processing and analysis, as consumers only receive the data they need, and the system can be scaled horizontally by create new topics for new shares.

Splitting the data by region is a good compromise for the project, as it allows us to demonstrate the system's capabilities without the need for a large number of Kafka topics. In our project, each region has its own Kafka topics for the tick data, EMA results, and advisories (buy/sell signals). This design choice allows for efficient data processing and analysis, as each region's data can be processed independently and in parallel. The use of Kafka topics for each region ensures that the system can scale horizontally by adding more Kafka brokers and partitions as needed, enabling the system to handle large volumes of data and provide low-latency processing.

## Flink for Real-time Analytics
Apache Flink is used for real-time analytics to process the high-frequency market events in 5-minute windows. The decision to use Flink for real-time analytics was driven by its ability to handle high-throughput data streams, provide low-latency processing, and support stateful computations. This is allows our system to process the event data in near real-time, enabling the EMA calculations and breakout pattern detection to be performed efficiently and accurately. Flink's support for event time processing and windowing allows the system to process the data based on the event timestamps, ensuring that the analysis is performed correctly and in the correct order.

Alternative to Flink we also considered using Apache Spark, which is a popular distributed data processing framework that provides similar capabilities for real-time analytics. But we decided to use Flink instead of Spark because of Flink's better support for event time processing and windowing, which are essential for processing high-frequency event data. Also beased on the performance comparison, Flink is more efficient in processing high-frequency event data compared to Spark wich is more suitable for batch processing.

## TimescaleDB for Data Storage
TimescaleDB stores processed data such as EMA results and advisories. As a time-series database, TimescaleDB is optimized for querying time-indexed data, making it an ideal choice for storing historical EMAs and advisories. This setup allows the system to provide historical insights and improve user experience. Although we currently use a single TimescaleDB instance, the system can easily scale horizontally by adding more instances behind a load balancer, enabling efficient handling of large datasets and low-latency queries.

## Web application
The web application provides a user-friendly interface for visualizing trends and advisories. We built it with React for UI flexibility and Tailwind CSS for rapid styling, benefiting from their large communities and rich ecosystems.

The web application includes charts for EMA visualization, tables for buy/sell advisories, and components for the latest share prices. Communication between the frontend and backend uses Socket.IO for real-time, bidirectional event streaming. The server subscribes to Kafka topics to receive processed data from Flink and tick data from the producer, then pushes this information to the client via Socket.IO for immediate display.

While we currently run a single instance of the web application, it can be horizontally scaled by adding more server instances. This would be straightforwardly automated using Kubernetes, simplifying deployment, scaling, and management. Given the project’s scope, we maintain a single instance for the demonstration, focusing on core functionality rather than large-scale scaling of the web layer.

# Implementation

Explain how the project was implemented, including the hardware/cloud services, programming tools,and GUI tools used

The implementation of the Market Trend Analyzer project was carried out on a local development environment, leveraging containerization for portability, and incorporating multiple programming languages, frameworks, and tools to achieve high-performance real-time data processing and analytics.

## Hardware and Environment

The entire system was developed and tested on a local machine running Ubuntu 22.04.5 LTS (64-bit). The hardware configuration included an HP EliteBook 810 G10 laptop with a 13th Gen Intel® Core™ i5-1335U (12-core) processor and 32 GB of RAM. This setup provided sufficient computational resources to run multiple Docker containers, execute high-throughput streaming processes, and serve a web interface, all on a single host.

## Containerization with Docker and Docker Compose

To ensure a consistent and reproducible environment, all system components were containerized using Docker. Docker Compose was used to define the multi-container setup, simplifying the orchestration of services and their dependencies. By specifying each service (e.g., producer, Kafka, Flink, TimescaleDB, and the web application) within a docker-compose.yml file, the system could be started and stopped with a single command, and developers could easily manage versions, ports, and resource allocations.

## Programming Languages and Tools

### Preprocessing with a Python Script

Before launching the entire system, a Python script is executed to prepare the input data for the real-time producer. The original dataset—often a large, single CSV file containing historical trading events—is first split into smaller, symbol- and region-specific CSV files. This preprocessing step involves:

- Input Parsing: The Python script reads the original large CSV file line by line.
- Data Partitioning: For each trading event, the script identifies its corresponding share symbol and region. It then routes the event to the appropriate output CSV, ensuring that each resulting file contains data for a specific symbol-region combination.
- File Organization: The script writes these smaller CSV files into a structured directory (e.g., data/day-08-11-21) for easy retrieval by the producer. This organization simplifies subsequent steps, as the producer can directly access time-sorted, symbol- and region-specific data without further filtering.

By performing this operation upfront, the system avoids complex filtering at runtime, ensuring that the real-time producer deals only with clean, targeted input data, which makes the simulation of live market streams more realistic and efficient.

### The Real-time Data Producer (Rust + Tokio)

Once the preprocessing step is complete and the smaller CSV files are in place, the Rust-based producer component handles the real-time data ingestion and streaming to Kafka. The producer’s main workflow, as illustrated by the provided main.rs and csv.rs code, involves several key steps:

1. Target Start Time Alignment: The producer reads a target start time from a given "topic"-like string (e.g., "08-11-2021 10:00:00") and calculates a time offset relative to the current wall-clock time. This offset aligns the historical trading events with the present, effectively recreating the live market conditions at the chosen start time.

2. Asynchronous Data Reading: Using the Tokio runtime for asynchronous execution, the producer spawns multiple worker tasks (TradingFileProcessor) to handle each CSV file in parallel.
  - Preprocessing Phase: Each worker first scans through its CSV to skip any events that should have already occurred before the target start time. It then synchronizes with other workers via a barrier, ensuring all files begin streaming events at the correct, unified start time.
  - Real-time Simulation: Once synchronized, each worker reads future-dated events from its CSV. Before emitting each event, it calculates how long it should wait (sleep) until the event’s designated timestamp occurs in "real-time." This ensures that events are replayed chronologically and at the correct intervals, mirroring the timing of the original trading day.

3. Data Serialization and Sending to Kafka: Each financial event is encapsulated in a FinancialTick structure and serialized using Protobuf (prost crates) to produce a compact binary message. This reduces overhead and increases performance compared to text-based formats like JSON.

After serialization, the producer uses the rdkafka library to send messages to Kafka. The chosen Kafka topic naming convention incorporates the region (e.g., region-ticks), allowing for logical partitioning of data. By enabling Snappy compression in the Kafka producer configuration (compression.type=snappy), the system further optimizes bandwidth usage and latency.

4. Concurrent Task Execution and Batching: The producer leverages Tokio’s asynchronous tasks to handle I/O operations without blocking, spawning separate tasks for sending messages to Kafka. It also manages batching and flushing strategies: while events are processed as they come due, the system periodically flushes buffered output to ensure low latency while balancing performance.

Monitoring and Logging: Throughout execution, the producer logs its progress—when messages are sent, if any errors occur, and how many events are skipped or processed. This feedback loop assists in debugging and verifying that the simulation accurately reflects real-time conditions.

### Messaging and Data Buffering (Kafka)
The Market Trend Analyzer relies on Apache Kafka to serve as a central messaging system, providing high-throughput, fault-tolerant buffering of event data between producers and downstream consumers. By decoupling data producers from consumers, Kafka ensures that each component can process data at its own rate without impacting the overall system performance or reliability.

#### Deployment and Configuration:
Kafka is deployed as a containerized service using the Bitnami kafka:latest Docker image. The Docker Compose configuration file (docker-compose.yml) sets up a single Kafka broker with its controller, along with several configuration parameters tailored to the system’s requirements. Notable environment variables include:

- Node and Process Configuration: *KAFKA_CFG_NODE_ID=0* and *KAFKA_CFG_PROCESS_ROLES=controller*,broker designate this node to act both as a controller and a broker.
- Listeners and Advertised Listeners: Multiple listeners are configured (*PLAINTEXT://:9092*, *CONTROLLER://:9093*, *EXTERNAL://:9094*) to accommodate internal and external access patterns. Internally, services connect via kafka:9092, while external tools, such as monitoring UIs, use localhost:9094.
- Protocol and Controller Quorum Settings: Mappings for security protocols and controller quorum voters ensure stable cluster management and leader election, critical for Kafka’s internal fault tolerance and scalability.
- Disabling Auto-Topic Creation: *KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false* prevents implicit topic creation, ensuring all topics are explicitly defined and managed. This approach encourages a controlled and reproducible infrastructure setup.

A designated volume (./configs/kafka) stores Kafka-related configuration files and scripts, facilitating maintainability and version control of the setup.

#### Topic Management and Initialization:
Before the system commences, topics are explicitly created via a script-based approach. The *create_topics.sh* script, executed inside the Kafka container, reads from a *topics.json* file that defines each topic’s name, partitions, and replicationFactor. By iterating through these definitions, the script ensures a clean, predictable set of Kafka topics is available upon startup.

This explicit topic creation step, combined with disabling auto-topic creation, ensures stable, versioned infrastructure. The chosen naming convention (e.g., *FR-ticks*, *FR-ema*, *FR-advisories*) reflects the data’s region and nature, providing a clear organizational structure. While data is partitioned by region in this implementation, the framework can be easily extended to partition by symbol or other criteria as needed.

#### Compression and Serialization:
In alignment with the system’s performance goals, producers use Snappy compression to reduce message sizes and improve throughput. Alongside Protobuf-based serialization, this configuration ensures efficient message transport. The combination of binary serialization and compression significantly optimizes both network utilization and end-to-end latency, enabling Kafka to handle continuous, high-frequency event streams effectively.

#### Monitoring and Observability:
During the development stage a Kafka UI tool (kafka-ui service) is used for monitoring and maintaining the Kafka service. The Kafka UI simplifies the process of validating system behavior, confirming that producers are sending data as intended and consumers are receiving it, thereby enhancing overall transparency and operational confidence.


### Stream Processing and Analytics (Flink)
...


### Storage and Querying (TimescaleDB)
...

### Web Application and Front-End Integration



# Performance Evaluation

Assess the system’s performance, including its correctness (e.g., whether query results are accurate), scalability (how the system performs with varying resources, such as CPU, or workloads, such as events per second), and resource utilization (e.g., GPU and CPU usage).

# Conclusion

Summarize the project and its contributions, and discuss potential future work.

# References
